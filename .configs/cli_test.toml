# Compose trainer, module, and datamodule factories for a single run.
# type: int | None
seed = 42
# type: <class 'bool'>
is_debug = false
# type: <class 'bool'>
verbose = true
# type: <class 'str'>
run_name = "alexnet-train-01"
# type: <enum 'Stage'>
stage = "train"
# type: <class 'traenslenzor.doc_classifier.configs.path_config.PathConfig'>

[trainer_config]
# type: <class 'bool'>
is_debug = false
# type: <class 'bool'>
fast_dev_run = false
# type: <class 'str'>
accelerator = "auto"
# type: int | str | collections.abc.Sequence[int]
devices = 1
# type: str | None
strategy = "auto"
# type: int | None
max_epochs = 10
# type: Union[Literal, Literal, Literal]
precision = "32-true"
# type: <class 'int'>
accumulate_grad_batches = 1
# type: <class 'int'>
log_every_n_steps = 50
# type: <class 'int'>
check_val_every_n_epoch = 1
# type: <class 'traenslenzor.doc_classifier.lightning.lit_trainer_callbacks.TrainerCallbacksConfig'>
use_wandb = true

    [trainer_config.callbacks]
    # type: <class 'bool'>
    use_model_checkpoint = false
    # type: <enum 'Metric'>
    checkpoint_monitor = "val/loss"
    # type: <class 'str'>
    checkpoint_mode = "min"
    # type: <class 'str'>
    checkpoint_filename = "epoch={epoch}-val_loss={val/loss:.2f}"
    # type: <class 'int'>
    checkpoint_save_top_k = 1
    # type: <class 'bool'>
    use_early_stopping = false
    # type: <enum 'Metric'>
    early_stopping_monitor = "val/loss"
    # type: <class 'str'>
    early_stopping_mode = "min"
    # type: <class 'int'>
    early_stopping_patience = 5
    # type: <class 'bool'>
    use_lr_monitor = false
    # type: <class 'str'>
    lr_logging_interval = "epoch"
    # type: <class 'bool'>
    use_rich_progress_bar = true
    # type: <class 'bool'>
    use_tqdm_progress_bar = false
    # type: <class 'int'>
    tqdm_refresh_rate = 1
    # type: <class 'bool'>
    use_rich_model_summary = true
    # type: <class 'int'>
    rich_summary_max_depth = 1
    # type: <class 'bool'>
    use_backbone_finetuning = false
    # type: <class 'int'>
    backbone_unfreeze_at_epoch = 10
    # type: <class 'bool'>
    backbone_train_bn = true
    # type: <class 'bool'>
    use_timer = false
    # type: <class 'str'>
    timer_interval = "step"

    [trainer_config.wandb_config]
    # W&B configuration for experiment tracking


# Hyperparameter tuning configuration (batch size and learning rate optimization)
[tuner_config]
# type: <class 'bool'>
use_batch_size_tuning = false
# type: <class 'str'>
batch_size_mode = "binsearch"
# type: <class 'int'>
batch_size_init_val = 64
# type: <class 'int'>
batch_size_steps_per_trial = 20
# type: <class 'int'>
batch_size_max_trials = 15
# type: <class 'bool'>
use_learning_rate_tuning = false
# type: <class 'float'>
lr_min = 5.0e-5
# type: <class 'float'>
lr_max = 5.0e-3
# type: <class 'int'>
lr_num_training = 100
# type: <class 'bool'>
update_model_lr = true
# type: <class 'bool'>
verbose = true
# type: <class 'bool'>
is_debug = false


[module_config]
# type: <class 'int'>
num_classes = 16
# type: <enum 'BackboneType'>
backbone = "alexnet"
# type: <class 'bool'>
train_head_only = false
# type: <class 'bool'>
use_pretrained = true
# type: <class 'traenslenzor.doc_classifier.lightning.lit_module.OptimizerConfig'>

    [module_config.optimizer]
    # type: <class 'float'>
    learning_rate = 0.0005
    # type: <class 'float'>
    weight_decay = 0.0001
    # type: <class 'traenslenzor.doc_classifier.lightning.lit_module.OneCycleSchedulerConfig'>

    [module_config.scheduler]
    # type: <class 'float'>
    max_lr = 0.01
    # type: <class 'float'>
    base_momentum = 0.85
    # type: <class 'float'>
    max_momentum = 0.95
    # type: <class 'float'>
    div_factor = 25.0
    # type: <class 'float'>
    final_div_factor = 10000.0
    # type: <class 'float'>
    pct_start = 0.3
    # type: Literal[cos, linear]
    anneal_strategy = "cos"
    # type: <class 'traenslenzor.doc_classifier.lightning.lit_datamodule.DocDataModuleConfig'>

[datamodule_config]
# type: <class 'int'>
batch_size = 32
# type: <class 'int'>
num_workers = 15
# type: <class 'bool'>
pin_memory = true
# type: <class 'bool'>
is_debug = false
# type: <class 'bool'>
verbose = true
