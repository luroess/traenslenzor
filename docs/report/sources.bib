@inproceedings{iso18004,
  title     = {{ISO/IEC 18004: Information technology -- Automatic identification and data capture techniques -- QR code bar code symbology specification}},
  booktitle = {ISO/IEC 18004:2000},
  author    = {{International Organization for Standardization}},
  year      = {2000},
}

@book{balzert_lehrbuch_2011,
	location = {Heidelberg},
	edition = {3},
	title = {Lehrbuch der Softwaretechnik: Entwurf, Implementierung, Installation und Betrieb},
	isbn = {978-3-8274-2246-0},
	series = {{SpringerLink} Bücher},
	shorttitle = {Lehrbuch der Softwaretechnik},
	publisher = {Spektrum Akademischer Verlag},
	author = {Balzert, Helmut},
	date = {2011},
	file = {Exemplare\: Lehrbuch der Softwaretechnik\: Entwurf, Implementierung, Installation und Betrieb - DHRV Ravensburg:/home/felsch01/Zotero/storage/AD6RLC46/(DE-627)1651019266.html:text/html},
}

@article{einstein1905,
  author  = {Albert Einstein},
  title   = {Does the Inertia of a Body Depend Upon Its Energy Content?},
  journal = {Annalen der Physik},
  year    = {1905},
  volume  = {18},
  pages   = {639--641}
}

@InProceedings{Ma_2018_CVPR,
  author    = {Ma, Ke and Shu, Zexuan and Bai, Jue Wang and Wang, Liliang and Liu, Dimy},
  title     = {DocUNet: Document Image Unwarping via A Stacked U-Net},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2018}
}

@InProceedings{Das_2019_ICCV,
  author    = {Das, Arindam and Ma, Ke and Shu, Zexuan and Kannan, Ankush and Samaras, Dimitris},
  title     = {DewarpNet: Single-Image Document Dewarping With Stacked 3D and 2D Regression Networks},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  month     = {October},
  year      = {2019}
}

@inproceedings{Verhoeven:UVDoc:2023,
  author    = {Verhoeven, Floor and Magne, Tanguy and Sorkine-Hornung, Olga},
  title     = {UVDoc: Neural Grid-based Document Unwarping},
  year      = {2023},
  isbn      = {9798400703157},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3610548.3618174},
  doi       = {10.1145/3610548.3618174},
  booktitle = {SIGGRAPH Asia 2023 Conference Papers},
  articleno = {68},
  numpages  = {10},
  location  = {Sydney, NSW, Australia},
  series    = {SA '23}
}

@online{noauthor_paddlepaddlepaddle_nodate,
	title = {{PaddlePaddle}/Paddle: {PArallel} Distributed Deep {LEarning}: Machine Learning Framework from Industrial Practice （『飞桨』核心框架，深度学习\&机器学习高性能单机、分布式训练和跨平台部署）},
	url = {https://github.com/PaddlePaddle/Paddle/pull/76699},
	urldate = {2026-01-08},
	file = {PaddlePaddle/Paddle\: PArallel Distributed Deep LEarning\: Machine Learning Framework from Industrial Practice （『飞桨』核心框架，深度学习&机器学习高性能单机、分布式训练和跨平台部署）:/home/schlafel/Zotero/storage/XFM2DVF6/76699.html:text/html},
}

@online{schmid_google_2025,
	title = {Google Gemma 3 Function Calling Example},
	url = {https://www.philschmid.de/gemma-function-calling},
	abstract = {Learn how to use function calling with Google {DeepMind} Gemma 3 27B It},
	author = {Schmid, Philipp},
	urldate = {2026-01-17},
	date = {2025-03-14},
	langid = {english},
	file = {Snapshot:/home/schlafel/Zotero/storage/AK8WJBSD/gemma-function-calling.html:text/html},
}

@online{noauthor_gemma34b_nodate,
	title = {gemma3:4b},
	url = {https://ollama.com/gemma3:4b},
	shorttitle = {gemma3},
	abstract = {The current, most capable model that runs on a single {GPU}.},
	urldate = {2026-01-17},
	file = {Snapshot:/home/schlafel/Zotero/storage/AGWX6M2Y/gemma34b.html:text/html},
}

@online{noauthor_llama31_nodate,
	title = {llama3.1},
	url = {https://ollama.com/llama3.1},
	abstract = {Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes.},
	urldate = {2026-01-17},
	file = {Snapshot:/home/schlafel/Zotero/storage/PMGAXQKL/llama3.html:text/html},
}

@online{noauthor_llama32_nodate,
	title = {llama3.2},
	url = {https://ollama.com/llama3.2},
	abstract = {Meta's Llama 3.2 goes small with 1B and 3B models.},
	urldate = {2026-01-17},
	file = {Snapshot:/home/schlafel/Zotero/storage/JLLZGCNI/llama3.html:text/html},
}

@online{noauthor_qwen3_nodate,
	title = {qwen3},
	url = {https://ollama.com/qwen3},
	abstract = {Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts ({MoE}) models.},
	urldate = {2026-01-17},
	file = {Snapshot:/home/schlafel/Zotero/storage/WK748XHD/qwen3.html:text/html},
}

@online{noauthor_gpt-oss_nodate,
	title = {gpt-oss},
	url = {https://ollama.com/gpt-oss},
	abstract = {OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.},
	urldate = {2026-01-17},
	file = {Snapshot:/home/schlafel/Zotero/storage/WK748XHD/qwen3.html:text/html},
}

@online{noauthor_deepseek-r1_nodate,
	title = {gpt-oss},
	url = {https://ollama.com/deepseek-r1},
	abstract = {DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.},
	urldate = {2026-01-17},
	file = {Snapshot:/home/schlafel/Zotero/storage/WK748XHD/qwen3.html:text/html},
}

@techreport{pep703,
  author       = {Sam Gross},
  title        = {PEP 703: Making the Global Interpreter Lock Optional in CPython},
  url          = {\url{https://peps.python.org/pep-0703/}},
  year         = {2023},
  type   	   = {PEP},
  note         = {Accepted Python Enhancement Proposal},
  organization = {Python Software Foundation}
}

@inproceedings{ocr-comparison,
    title = "Open-Source {OCR} Libraries: A Comprehensive Study for Low Resource Language",
    author = "Nazeem, Meharuniza  and
      R, Anitha  and
      S, Navaneeth  and
      R. R, Rajeev",
    editor = "Lalitha Devi, Sobha  and
      Arora, Karunesh",
    booktitle = "Proceedings of the 21st International Conference on Natural Language Processing (ICON)",
    month = dec,
    year = "2024",
    address = "AU-KBC Research Centre, Chennai, India",
    publisher = "NLP Association of India (NLPAI)",
    url = "https://aclanthology.org/2024.icon-1.48/",
    pages = "416--421",
    abstract = "This paper reviews numerous OCR programs and libraries employed for optical character recognition tasks. Tesser- act OCR, an open-source program that supports multiple lan- guages and image formats, is highlighted for its accuracy and adaptability. Python-based libraries like EasyOCR, MMOCR, and PaddleOCR are also mentioned, which provide user-friendly interfaces and trained models for text extraction, detection, and recognition. EasyOCR emphasizes ease of use and sim- plicity, while MMOCR and PaddleOCR offer comprehensive OCR capabilities and support for a wide range of languages. According to our study, which evaluates various OCR libraries, Tesseract OCR performs remarkably well in terms of accuracy for Indian languages like Malayalam. We focused on five OCR libraries{---}Tesseract OCR, MMOCR, PaddleOCR, EasyOCR, and Keras OCR{---}and tested them across several languages, including English, Hindi, Arabic, Tamil, and Malayalam. During our comparison, we found that Tesseract OCR was the only library that supported the Malayalam language. While the other libraries did not support Malayalam, Tesseract OCR performed well across all tested languages, achieving accuracy rates of 92{\%} in English, 93{\%} in Hindi, 78{\%} in Tamil, 74{\%} in Arabic, and 93{\%} in Malayalam."
}

@online{suvorovResolutionrobustLargeMask2021,
  title = {Resolution-Robust {{Large Mask Inpainting}} with {{Fourier Convolutions}}},
  author = {Suvorov, Roman and Logacheva, Elizaveta and Mashikhin, Anton and Remizova, Anastasia and Ashukha, Arsenii and Silvestrov, Aleksei and Kong, Naejin and Goka, Harshith and Park, Kiwoong and Lempitsky, Victor},
  date = {2021-11-11},
  eprint = {2109.07161},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2109.07161},
  url = {http://arxiv.org/abs/2109.07161},
  urldate = {2025-10-19},
  abstract = {Modern image inpainting systems, despite the significant progress, often struggle with large missing areas, complex geometric structures, and high-resolution images. We find that one of the main reasons for that is the lack of an effective receptive field in both the inpainting network and the loss function. To alleviate this issue, we propose a new method called large mask inpainting (LaMa). LaMa is based on i) a new inpainting network architecture that uses fast Fourier convolutions (FFCs), which have the image-wide receptive field; ii) a high receptive field perceptual loss; iii) large training masks, which unlocks the potential of the first two components. Our inpainting network improves the state-of-the-art across a range of datasets and achieves excellent performance even in challenging scenarios, e.g. completion of periodic structures. Our model generalizes surprisingly well to resolutions that are higher than those seen at train time, and achieves this at lower parameter\&time costs than the competitive baselines. The code is available at \textbackslash url\{https://github.com/saic-mdal/lama\}.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
}
